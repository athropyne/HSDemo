# HSDemo

Демонстрационный проект (переписываемая с нуля укороченная версия проекта на проде с другими технологиями и подходом).

## Кратко

Проект предназначен для лабораторных морфологических исследований.
Основные сущности **Пользователь**, **Команда**, **Участники команды**, **Случаи**, **Материалы**, **Хранилища**.

**Пользователь** - любой зарегистрированный человек, может создать **команду** и приглашать в нее **участников**. 
**Участники** могут создавать **случаи** с описанием проблемы и загружать в нее **материалы** (в разработке. в этой версии будут поддерживаться только снимки с электронных микроскопов типа aperio - .svs файлы) .
**Материалы** будут загружаться в **хранилища**, которые будут представлять массив реплик отдельного сервиса, 
хранящего материалы локально (*). **Хранилища** будут обладать функциональностью по автоматической саморегистрации в системе,
проверкой на живучесть, клонированием материалов в случае аварийного уменьшения их популяции,
а так же контролем доступной памяти для загрузки материалов. Основная задача хранилища -
временно хранить оригиналы снимков с электронного микроскопа и отдавать запрошенные регионы (будет заточено под библиотеку OpenSeadragon.js - для просмотра изображений глубокого масштабирования. https://openseadragon.github.io/)

#### **(*)** Почему не s3 ?
Материалы могут быть огромных размеров, до 20-25 ГБ, 
а использоваться по назначению короткое время. Достать нужный регион без обработки оригинального файла .svs невозможно.
Поэтому в s3 он просто не нужен. Второй подход может заключаться в хранении всех возможных регионов (чанков огромного изображения) в s3,
но таких регионов могут быть десятки миллионов (десятки миллионов файлов обработать, передать по http протоколу, хранить в нескольких экземплярах и в худшем случае все это начинать удалять через полчаса).
Поэтому будет реализована система похожая на s3, но с возможностью обработки материала на месте.

Документация будет доступна после окончания работы над первой рабочей версии.

Если нужно запустить прям сейчас:

* В проекте используются **MongoDB 6.0**, **Redis 7.0**, **Python 3.11** -- устанавливаем ( либо запускаем в контейнерах, конфигурации запуска пока нет )
* устанавливаем зависимости ```pip install -r requirements.txt```
* если все запустилось и вы увидели что то вроде  
*INFO   Uvicorn running on http://localhost:8000 (Press CTRL+C to quit)*
значит все работает. перейдите по адресу http://localhost:8000/docs для просмотра openAPI документации. 

На данный момент работают модули пользователей, команд, участников команд и случаев (без материалов). 
Используется пассивное кэширование (пока не везде и пока пассивное. т.е. при любой отсутствующей информации в кэше она считается недостоверной и происходит запрос в базу).


**!!!  Первичная документация в openAPI может отличаться от действительного функционала так как редактировалась раньше чем основной код**

